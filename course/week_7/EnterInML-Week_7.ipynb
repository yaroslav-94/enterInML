{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этапы анализа данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Понимание задачи\n",
    "Тип задачи:\n",
    "- регрессия $Y \\in \\mathbb{R}$\n",
    "- классификация $Y =\\{0,1\\}$\n",
    "- кластеризация Y=?\n",
    "\n",
    "Метрики:\n",
    "- Регрессия \n",
    "    - MSE $\\frac{1}{l}\\sum_{i=1}^l(a(x_x)-y_i)^2$\n",
    "    - MAE $\\frac{1}{l}\\sum_{i=1}^l|a(x_x)-y_i|$\n",
    "- Классификация\n",
    "    - доля верных ответов $\\frac{1}{l}\\sum_{i=1}^l[a(x_i)=y_i]$\n",
    "    - точность и полнота\n",
    "    - AUC-ROC, AUC-PRC\n",
    "- Кластеризация\n",
    "    - зависит от задачи\n",
    "    \n",
    "Бизнес-метрики: убедиться, что зависит от маинного обучения, а не от других факторов\n",
    "\n",
    "\n",
    "### Данные\n",
    "Типы признаков:\n",
    "- числовые\n",
    "- категориальные\n",
    "- текстовые\n",
    "- изображение\n",
    "- координаты\n",
    "\n",
    "\n",
    "### Формирование признаков\n",
    "Задача: получить матрицу объекты-признаки  \n",
    "Преобразование числовых признаков  \n",
    "Извлечение числовых признаков из сырых данных  \n",
    "\n",
    "\n",
    "###  Предобработка данных \n",
    "Данные могут быть грязными:\n",
    "- выбросы\n",
    "- шумы в признаках\n",
    "- пропущенные значения\n",
    "\n",
    "Помнить: мусор на входе - мусор на выходе\n",
    "\n",
    "\n",
    "### Построение алгоритма\n",
    "Основные семейства в задачах обучения с учителем:\n",
    "- линейные модели\n",
    "- композиции деревьев (градаентны бустинг, случайный лес)\n",
    "- нейронные сети \n",
    "\n",
    "Может помочь:\n",
    "- отбор признаков\n",
    "- понижение размерности\n",
    "\n",
    "\n",
    "### Оценивание качества\n",
    "Оценка качества алгоритма и настройка гиперпараметров:\n",
    "- отложенная выборка\n",
    "- кросс-валидация\n",
    "- разбивание данных на блоки\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с числовыми признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Числовые признаки\n",
    "Готовы к использованию, но их можно улучшить. Например, получая новый признак из страых с помощью линейной комбинации\n",
    "\n",
    "\n",
    "### Масштабирование признаков\n",
    "- среднее и стандартное отклонение: $\\tilde{x}^j=\\frac{x^j-\\mu}{\\sigma}$\n",
    "- нормировка на отрезок (0,1]: $\\tilde{x}^j=\\frac{x^j-min(x^j)}{max(x^j)-min(x^j)}$\n",
    "\n",
    "\n",
    "### Трансформация признаков\n",
    "Качество выше, если распределение близко к нормальному  \n",
    "Пример, логарифмирование неотрицательных признаков $\\tilde{x}^j=log(x^j+1)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с категориальными и текстовыми признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категориальные признаки\n",
    "Dummy-кодирование:\n",
    "- признак $x^j$ принимает значения из множества $U=\\{u_1,...,u_m\\}$\n",
    "- создание новых признаков-индикаторов $x^{j1},...,x^{jm}$: $x^{jk}=[x^k=u_k]$\n",
    "\n",
    "Проблема: уникалные категории (алгоритму трудно подобрать зависимость)\n",
    "Решение: объединить редкие категории в одну $\\sum_{i=1}^l[x^j_i=u]<r$\n",
    "\n",
    "При большом количестве уникальных значений для признаков возникнет проблема обучения алгоритма\n",
    "\n",
    "\n",
    "### Счетчики\n",
    "Пример применения:\n",
    "- задача классификации $Y=\\{0,1\\}$\n",
    "- оценка вероятности первого класса при уловии значения признака: $c(u_k)=p(y=1|x^j=u_k)=\\frac{\\sum_{i=1}^l [x^j_i=u_k][y_i=1]}{\\sum_{i=1}^l [x^j_i=u_k]}$\n",
    "- заменяем категориалный признак $x^j$ на числовой $\\tilde{x}^j$: $\\tilde{x}^j_i=c(x_i^j)$\n",
    "- для борьбы с переобучением можно вычислять счетчики с помощью-кросс валидации \n",
    "     - выборка разбивается на k-частей\n",
    "     - для i-й части используются оценки вероятностей, полученные по остальным частям\n",
    "     - для контрольной выборки используются оценки, полученные по всей обучающей выборке\n",
    "\n",
    "\n",
    "### Текстовые признаки\n",
    "Значение признака $x^j$ - последовательность слов $(w_1, w_2,...)$\n",
    "\n",
    "Мешок слов:\n",
    "- выводы о тексте можно делать даже по перемешанным словам\n",
    "- слова из текста принадлежат словарю $W=\\{w_1,...,w_m\\}$\n",
    "- Создадим m новых признаков-индикаторов: $x^{j_1},...,x^{j_m}$: $x^{jk}=n_{w_k}$, $n_{w_k}$ - число вхождения слова $w_k$ в документ\n",
    "- аналог Dummy-кодирования, но теперь несколько признаков могут быть больше нуля\n",
    "\n",
    "\n",
    "### TF-IDF\n",
    "Вычислять не количество вхождений слов, а оценки их важности для текста\n",
    "- чем чаще слово встречается в документе, тем оно важнее\n",
    "- чем реже слово встречается в остальных документах, тем оно важнее\n",
    "\n",
    "$n_{iw}$ (term frequency) - число вхождения слова w в текст $x^j_i$\n",
    "$N_w$ (document frequency) - число текстов, содержащих w\n",
    "\n",
    "Важность слова w для документа $x^j_i$: $TF-IDF(i, w)=n_{dw}*log(\\frac{l}{N_w})$, TF(i, d)=$n_{dw}$ - term frequency, IDF(w)= $log(\\frac{l}{N_w})$ - document frequency\n",
    "\n",
    "\n",
    "### N-граммы\n",
    "Часто важны не только слова, но и словосочетания\n",
    "\n",
    "N-граммы:\n",
    "- добавим в словарь W все возможные пары слов\n",
    "- добавим признаки-индикаторы для пар слов: $x_i^{jks}=[(w_k, w_s)\\in x_i^j]$\n",
    "- многие пары не встретились ни разу - выбрасываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация выбросов\n",
    "Статистики:\n",
    "- первая квартиль $Q_1:\\ \\frac{1}{l}\\sum_{i=1}^l[x_i\\leq Q_1]=0.25$\n",
    "- третья квартиль $Q_3:\\ \\frac{1}{l}\\sum_{i=1}^l[x_i\\leq Q_3]=0.75$\n",
    "- интерквартильный размах: $IQR=Q_3-Q1$\n",
    "\n",
    "Эвристика: выбросы лежат за пределами отрезка $[Q_1-1.5IQR,Q_3+1.5IQR]$\n",
    "\n",
    "\n",
    "### Пропуски в числовых признаках\n",
    "Пропуски в числовых признаках:\n",
    "- замена на среднее\n",
    "- замена на медиану\n",
    "\n",
    "Пропуски в категориальных признаках:\n",
    "- замена на самое популярное значение\n",
    "- замена на новое значение\n",
    "- случайный выбор из распределения значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценивание качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка качества алгоритма\n",
    "- обучающая выборка (алгоритм настроен на этих данных, при переобучении качество будет хорошим при отсутствии обобщающей способности)\n",
    "- по отложенной выборке\n",
    "- с помщью кросс-валидации\n",
    "\n",
    "\n",
    "### Отложенная выборка\n",
    "Выборка разбивается на обучающую и валидационную\n",
    "\n",
    "Особенности:\n",
    "- если обучающая выборка маленькая, то оценка качества будет слишком пессимистичной\n",
    "- если валидационная выборка маленькая, то оценка будет неточной\n",
    "- 70/30\n",
    "\n",
    "Проблемы:\n",
    "- результат сильно зависит от разбиения - каждый объект участвует или только в обучении, или только в валидации\n",
    "- если сравнивать много моделей, то есть риск подгонки под конкретную валидационную выборку\n",
    "\n",
    "\n",
    "### Кросс-валидация\n",
    "Выборка разбивается на k частей. Каждая по очереди выступает как валидацинная\n",
    "\n",
    "Выбор количества частей для разбиения:\n",
    "- небольшие k - пессимистичные, но точные\n",
    "- большие k - несмещенныес большой дисперсией\n",
    "- k=5 или 10\n",
    "\n",
    "Проблема:\n",
    "- нужно обучать k алгоритмов\n",
    "\n",
    "\n",
    "### Разбивание выборки\n",
    "Методы предполагают, что все объекты принадлежат одному распределению и независимы\n",
    "\n",
    "\n",
    "### Отбор признаков\n",
    "- выбирается обучающая и тестовая выборки в кросс-валидации\n",
    "- находятся оптимальные признаки по обучающей выборке\n",
    "- проверяется качество на тестовой выборке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные методы\n",
    "- регрессия $Y=\\mathbb{R}$ - линейная регрессия: $a(x)=\\langle w, x \\rangle,\\ Q(w)=\\sum_{i=1}^l(\\langle w, x \\rangle-y_i)^2 \\to min_w$\n",
    "- классификация Y={-1,+1} - логистическая регресия: $a(x)=sign\\langle w, x \\rangle,\\ Q(w)=\\sum_{i=1}^llog(exp(-y_i\\langle w, x \\rangle))\\to min_w$\n",
    "\n",
    "\n",
    "Регуляризация для штрафов за переусложнение модели:\n",
    "- $Q(w)+\\sum_{j=1}^d w_j^2\\to min_w$\n",
    "- $Q(w)+\\sum_{j=1}^d |w_j|\\to min_w$\n",
    "\n",
    "Преимущества:\n",
    "- мало параметров, быстро обучаются\n",
    "- могут настраиваться стохастическим градиентым спуском, не требуют хранения выборки в памяти\n",
    "- инерпретируемые\n",
    "- хорошо подходят для задач с малым числом объектов и большим числом признаков\n",
    "- хорошоо подходят для разреженных данных\n",
    "\n",
    "Недостатки:\n",
    "- низкая выразительность\n",
    "- требуют предобработки данных\n",
    "\n",
    "\n",
    "### Случайные леса\n",
    "Средний прогноз решающих деревьев: $a(x)=\\frac{1}{N}\\sum_{n=1}^Nb_n(x)$\n",
    "\n",
    "Обучение:\n",
    "- деревья строятся незавмисимо\n",
    "- каждое дерево обучается по подвыборке объектов\n",
    "- лучший признак для разбиния в верщине выбирается из подмножества признаков\n",
    "- дерево строится до тех пор, пока в каждом листе не окажется по одному объекту\n",
    "- отдельные деревья крайне переобучены, усреднение прогнозов устраняет проблему\n",
    "\n",
    "Преимущества:\n",
    "- сильный алгоритм, способен восстанавливать сложные зависимости\n",
    "- не требует масштабирования признаков\n",
    "- устойчив к шумам в признаках\n",
    "- легко распараллелить: каждое дерево обучается независимо\n",
    "- очень мало гиперпараметров\n",
    "- нет переобучения при увеличении числа деревьев\n",
    "\n",
    "Недостатки:\n",
    "- могут долго обучаться из-за большой глубины\n",
    "- из-за большого размера долго строится предсказание\n",
    "- трудно настраивать на сложные меры качества\n",
    "- плохо подходит для разреженных данных\n",
    "\n",
    "\n",
    "### Градиентный бустинг над деревьями\n",
    "Сумма прогнозов решающих деревьев: $a(x)=\\sum_{n=1}^N\\alpha_nb_n(x)$\n",
    "\n",
    "Обучение:\n",
    "- деревья строятся последовательно\n",
    "- деревья ограничиваются по глубине\n",
    "- каждое следующее дерево приближает градиент ошибки построенной композици\n",
    "\n",
    "Преимущества:\n",
    "- сильный алгоритм, способен восстанавливать сложные зависимости\n",
    "- не требует масштабирования признаков\n",
    "- устойчив к шумам в признаках\n",
    "- может настраиваться на любую дифференцируемую меру качества\n",
    "- настраивается быстрее случайного леса\n",
    "\n",
    "Недостатки:\n",
    "- может переобучаться\n",
    "- необходимо подбирать число деревьев\n",
    "- плохо подходит для разреженных данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
