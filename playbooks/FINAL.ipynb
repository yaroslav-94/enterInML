{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг на деревьях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1-3\n",
    "Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).\n",
    "\n",
    "Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.\n",
    "\n",
    "Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time    77677\n",
      "dtype: int64\n",
      "first_blood_team    77677\n",
      "dtype: int64\n",
      "first_blood_player1    77677\n",
      "dtype: int64\n",
      "first_blood_player2    53243\n",
      "dtype: int64\n",
      "radiant_bottle_time    81539\n",
      "dtype: int64\n",
      "radiant_courier_time    96538\n",
      "dtype: int64\n",
      "radiant_flying_courier_time    69751\n",
      "dtype: int64\n",
      "radiant_first_ward_time    95394\n",
      "dtype: int64\n",
      "dire_bottle_time    81087\n",
      "dtype: int64\n",
      "dire_courier_time    96554\n",
      "dtype: int64\n",
      "dire_flying_courier_time    71132\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_train.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire'], inplace = True, axis = 1)\n",
    "a = X_train.count()\n",
    "z = X_train.shape[0]\n",
    "for i in range (0,X_train.shape[1]-1,1):\n",
    "    if (a[i]<z): print(a[i:i+1:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список неполностью заполненных значений с указанием реальной обстановки/причины:\n",
    "\n",
    "    first_blood_time               77677   За первые 5 минут не всегда есть первое убийство\n",
    "\n",
    "    first_blood_team               77677   За первые 5 минут не всегда есть первое убийство=> нет всегда такой команды\n",
    "\n",
    "    first_blood_player1            77677   За первые 5 минут не всегда есть первое убийство=> нет всегда и такого игрока\n",
    "\n",
    "    first_blood_player2            53243   За первые 5 минут не всегда есть первое убийство=> а вот помощников еще меньше\n",
    "\n",
    "    radiant_bottle_time            81539   За первые 5 минут не куплен данный предмет рэдиантами\n",
    "\n",
    "    radiant_courier_time           96538   За первые 5 минут не куплен данный предмет рэдиантами\n",
    "\n",
    "    radiant_flying_courier_time    69751   За первые 5 минут не куплен данный предмет рэдиантами\n",
    "\n",
    "    radiant_first_ward_time        95394   За первые 5 минут не куплен/установлен данный предмет рэдиантами\n",
    "\n",
    "    dire_bottle_time               81087   За первые 5 минут не куплен данный предмет даирами\n",
    "\n",
    "    dire_courier_time              96554   За первые 5 минут не куплен данный предмет даирами\n",
    "\n",
    "    dire_flying_courier_time       71132   За первые 5 минут не куплен данный предмет даирами\n",
    "\n",
    "    dire_first_ward_time           95404   За первые 5 минут не куплен данный предмет даирами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4\n",
    "Какой столбец содержит целевую переменную? Запишите его название.\n",
    "\n",
    "Целевая переменная - 'radiant_win'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?\n",
    "\n",
    "### Итог\n",
    "Классификатор настраивается довольно долго. Время настройки растет как функция от времени. Достигнут лимит качества, так как при увеличении числа деревьев качество меняется довольно незначительно. Скорее всего качество будет расти, но вскоре будет достигнут лимит. (возможно, предел находится в районе 70-72 %)\n",
    "\n",
    "Время для обучения 10 деревьев  0:01:02.519576; \n",
    "0.6645339957137539\n",
    "\n",
    "Время для обучения 20 деревьев  0:01:56.767678; \n",
    "0.6819901320753952\n",
    "\n",
    "Время для обучения 30 деревьев 0:03:05.319599; \n",
    "0.6891167972431018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время для обучения 10 деревьев  0:00:51.989710\n",
      "0.6654458562456946\n",
      "Время для обучения 20 деревьев  0:01:33.444589\n",
      "0.6818068818049412\n",
      "Время для обучения 30 деревьев 0:02:22.481791\n",
      "0.689971756375909\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire'], inplace = True, axis = 1)\n",
    "#scaler = StandardScaler()\n",
    "#X_test = scaler.fit_transform(X_test)\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "# Градиентный бустинг на деревьях решений\n",
    "start_time = datetime.datetime.now()\n",
    "GBC = GradientBoostingClassifier(n_estimators=10)#,max_depth = 3, learning_rate =0.1 )\n",
    "GBC.fit(X_test, y_test)\n",
    "a = cross_val_score(GBC, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print( 'Время для обучения 10 деревьев ', datetime.datetime.now() - start_time )\n",
    "print(a.mean())\n",
    "\n",
    "# Градиентный бустинг на деревьях решений\n",
    "start_time = datetime.datetime.now()\n",
    "GBC = GradientBoostingClassifier(n_estimators=20,max_depth = 3)#, learning_rate =0.1)\n",
    "GBC.fit(X_test, y_test)\n",
    "a = cross_val_score(GBC, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print( 'Время для обучения 20 деревьев ', datetime.datetime.now() - start_time )\n",
    "print(a.mean())\n",
    "\n",
    "# Градиентный бустинг на деревьях решений\n",
    "start_time = datetime.datetime.now()\n",
    "GBC = GradientBoostingClassifier(n_estimators=30,max_depth = 3)#, learning_rate =0.1)\n",
    "GBC.fit(X_test, y_test)\n",
    "a = cross_val_score(GBC, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print( 'Время для обучения 30 деревьев', datetime.datetime.now() - start_time )\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "### Итог\n",
    "Наилучшее качество получилось равным ~51.3%. Качество градиентного бучтинга значительно лучше (около 68.9%). Данная разница связана с тем, что бустинг на деревьях не зависит от представленных данных, тоесть от масштабирования, что играет существенную разницу для логистической регрессии. (Логистическая регрессия работает в несколько раз быстрее.) для регрессии 0:00:30.510173, для градиентного бустинга на 30 деревьях 0:03:05.319599\n",
    "\n",
    "При использовании масштабирования признаков качество вырастает до 71.6%. Что чуть больше чем у градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire'], inplace = True, axis = 1)\n",
    "\n",
    "# Нормировка выборки\n",
    "#X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "#Поиск лучшего значения для параметра\n",
    "best_value = 0\n",
    "i_best = 0\n",
    "start_time = datetime.datetime.now()\n",
    "for i in (0.01,0.1, 0.2, 0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1,1.2,1.3,1.4,1.5,2,3,4,5,6,7,8,9,10,15,20,50,100):\n",
    "    # Просто прогонка логистической регресии\n",
    "    \n",
    "    LR = LogisticRegression(penalty='l2',C=i).fit(X_test, y_test)\n",
    "    a = cross_val_score(LR, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "    if (a.mean()>best_value):\n",
    "        best_value = a.mean()\n",
    "        i_best = i\n",
    "print( 'Время для простой прогонки', datetime.datetime.now() - start_time )\n",
    "print(best_value, i_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?\n",
    "### Итог\n",
    "Качество не улучшилось при удалении этих столбцов, скорее всего содержащаяся там информация используется в плохом качестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire','lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "# Создание выборки для обучения. Масштабироание\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "#Поиск наилучшего значения для коэффициента логистической регрессии\n",
    "best_value = 0\n",
    "i_best = 0\n",
    "start_time = datetime.datetime.now()\n",
    "for i in (0.1, 0.2, 0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.1,1.2,1.3,1.4,1.5,2,3,4,5,6,7,8,9,10,15,20):\n",
    "    LR = LogisticRegression(penalty='l2',C=i).fit(X_test, y_test)\n",
    "    a = cross_val_score(LR, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "    if (a.mean()>best_value):\n",
    "        best_value = a.mean()\n",
    "        i_best = i\n",
    "print( 'Время для простой прогонки', datetime.datetime.now() - start_time )\n",
    "print(best_value, i_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).\n",
    "### Итог\n",
    "всего в игре 112 героев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "X_test['r1_hero'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.\n",
    "Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.\n",
    "### Итог\n",
    "Получился массив размером (97230, 204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "data = pd.read_csv(r\"D:\\works\\features/features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire', 'lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "# N — количество различных героев в выборке\n",
    "N = data['d2_hero'].max()\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test = np.hstack((X_test, X_pick))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5\n",
    "Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?\n",
    "### Итог\n",
    "Качество улучшилось 71.6% против 75.2%. Это объясняется тем, что информация, которая содержится в дополнительных столбцах, теперь используется по прямому назначению (появились более выигрышные и более играющие герои)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "data   = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire', 'lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "N = data['d2_hero'].max()\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test = np.hstack((X_test, X_pick))\n",
    "data = pd.DataFrame()\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits = 5, shuffle=True, random_state = 0)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "#Поиск наилучшего значения для коэффициента логистической регрессии\n",
    "best_value = 0\n",
    "i_best = 0\n",
    "\n",
    "for i in (0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 3, 5, 7, 10, 20, 50, 100):\n",
    "    start_time = datetime.datetime.now()\n",
    "    LR = LogisticRegression(penalty='l2',C=i).fit(X_test, y_test)\n",
    "    a = cross_val_score(LR, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "    if (a.mean()>best_value):\n",
    "        best_value = a.mean()\n",
    "        i_best = i\n",
    "    print( 'Время для простой прогонки', datetime.datetime.now() - start_time )\n",
    "print(best_value, i_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.\n",
    "Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).\n",
    "### Итог\n",
    "Максимальное значение для выигрыша 0.996517, для проигрыша 0.008591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение тренировочных данных и удаление части \"будущего\"\n",
    "X_train = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "data_train = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_train.fillna(0, inplace = True)\n",
    "y_train = X_train['radiant_win']\n",
    "X_train.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire', 'lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "#Чтение тестовых данных и удаление столбцов с героями\n",
    "X_test = pd.read_csv(r\"D:\\works\\features_test\\features_test.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "data_test = pd.read_csv(r\"D:\\works\\features_test\\features_test.csv\", index_col='match_id')\n",
    "X_test.drop(['lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', 'r5_hero','d1_hero', 'd2_hero','d3_hero',\n",
    "             'd4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "# Масштабирование даннх\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "kf = KFold(n_splits = 3, shuffle=True)\n",
    "kf.split(X_train, y_train)\n",
    "\n",
    "N = data_test['d2_hero'].max()\n",
    "X_pick_train = np.zeros((data_train.shape[0], N))\n",
    "X_pick_test = np.zeros((data_test.shape[0], N))\n",
    "\n",
    "# Добавление героев в тренировочную выборку\n",
    "for i, match_id in enumerate(data_train.index):\n",
    "    for p in range(5):\n",
    "        X_pick_train[i, data_train.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick_train[i, data_train.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1      \n",
    "X_train = np.hstack((X_train, X_pick_train))\n",
    "\n",
    "# Добавление героев в тестовую выборку\n",
    "for i, match_id in enumerate(data_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, data_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick_test[i, data_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1      \n",
    "X_test = np.hstack((X_test, X_pick_test))\n",
    "data_test = pd.DataFrame()\n",
    "\n",
    "#Обучение и построение предсказание для логистической регрессии\n",
    "LR = LogisticRegression(penalty='l2',C= 1).fit(X_train, y_train)\n",
    "a = pd.read_csv(r\"D:\\works\\features_test\\features_test.csv\", usecols = [0])\n",
    "a['radiant_win'] = LR.predict_proba(X_test)[:,1]\n",
    "a.to_csv(r\"D:\\works\\final_test.csv\", sep = ' ', header = False, index = False, mode ='w+')\n",
    "print(a.min(), a.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес классификатор \n",
    "0.6305000070125029; \n",
    "Время для 10 деревьев 0:00:54.525119\n",
    "\n",
    "0.6528236711683177; \n",
    "Время для 20 деревьев 0:01:29.975146\n",
    "\n",
    "0.669879466254194; \n",
    "Время для 30 деревьев 0:01:54.844569\n",
    "\n",
    "Скорость примерно похожа, но качество ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire'], inplace = True, axis = 1)\n",
    "#scaler = StandardScaler()\n",
    "#X_test = scaler.fit_transform(X_test)\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "kf.split(X_test, y_test)\n",
    "  \n",
    "start_time = datetime.datetime.now()    \n",
    "regr = RandomForestClassifier(n_estimators=10)#,random_state=1)\n",
    "a = cross_val_score(regr, X_test, y_test, scoring = 'roc_auc', cv = kf)\n",
    "print(a.mean())\n",
    "print( 'Время для 10 деревьев', datetime.datetime.now() - start_time )\n",
    "\n",
    "start_time = datetime.datetime.now()    \n",
    "regr = RandomForestClassifier(n_estimators=20)#,random_state=1)\n",
    "a = cross_val_score(regr, X_test, y_test, scoring = 'roc_auc', cv = kf)\n",
    "print(a.mean())\n",
    "print( 'Время для 20 деревьев', datetime.datetime.now() - start_time )\n",
    "\n",
    "start_time = datetime.datetime.now()    \n",
    "regr = RandomForestClassifier(n_estimators=30)#,random_state=1)\n",
    "a = cross_val_score(regr, X_test, y_test, scoring = 'roc_auc', cv = kf)\n",
    "print(a.mean())\n",
    "print( 'Время для 30 деревьев', datetime.datetime.now() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier\n",
    "Linear classifiers (SVM, logistic regression, a.o.) with SGD training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "data = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire', 'lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d5_hero'],inplace = True, axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "N = data['d2_hero'].max()\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test = np.hstack((X_test, X_pick))\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits = 5, shuffle=True, random_state = 0)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "start_time = datetime.datetime.now()  \n",
    "clf = linear_model.SGDClassifier(penalty='l2', max_iter = 2000)\n",
    "a = cross_val_score(clf, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print(a.mean())\n",
    "print( 'Время для аппроксимации для SGDClassifier', datetime.datetime.now() - start_time )\n",
    "\n",
    "#start_time = datetime.datetime.now()  \n",
    "#clf = linear_model.Perceptron(penalty='l2', max_iter = 100)\n",
    "#a = cross_val_score(clf, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "#print(a.mean())\n",
    "#print( 'Время для аппроксимации для персептрона', datetime.datetime.now() - start_time )\n",
    "\n",
    "#start_time = datetime.datetime.now()  \n",
    "#clf = linear_model.LinearSVC(penalty='l2', max_iter = 100)\n",
    "#a = cross_val_score(clf, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "#print(a.mean())\n",
    "#print( 'Время для аппроксимации для SVC', datetime.datetime.now() - start_time )\n",
    "\n",
    "# Градиентный бустинг на деревьях решений\n",
    "start_time = datetime.datetime.now()\n",
    "GBC = GradientBoostingClassifier(n_estimators=30,max_depth = 3)#, learning_rate =0.1)\n",
    "GBC.fit(X_test, y_test)\n",
    "a = cross_val_score(GBC, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print( 'Время для обучения 30 деревьев', datetime.datetime.now() - start_time )\n",
    "print(a.mean())\n",
    "\n",
    "# SVM classification\n",
    "start_time = datetime.datetime.now()  \n",
    "clf = SVC(kernel='linear', random_state=241)\n",
    "a = cross_val_score(clf, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print(a.mean())\n",
    "print( 'Время для аппроксимации для SVM', datetime.datetime.now() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтение данных и удаление части \"будущего\"\n",
    "X_test = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "data = pd.read_csv(r\"D:\\works\\features\\features.csv\", index_col='match_id')\n",
    "X_test.fillna(0, inplace = True)\n",
    "y_test = X_test['radiant_win']\n",
    "X_test.drop(['radiant_win', 'duration', 'tower_status_radiant','tower_status_dire','barracks_status_radiant',\n",
    "             'barracks_status_dire', 'lobby_type', 'r1_hero', 'r2_hero','r3_hero', 'r4_hero', \n",
    "             'r5_hero','d1_hero', 'd2_hero','d3_hero','d4_hero','d1_hero'],inplace = True, axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "N = data['d2_hero'].max()\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X_test = np.hstack((X_test, X_pick))\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Создание выборки для обучения\n",
    "kf = KFold(n_splits = 5, shuffle=True, random_state = 0)\n",
    "kf.split(X_test, y_test)\n",
    "\n",
    "start_time = datetime.datetime.now()  \n",
    "clf = SVC(kernel='rbf')\n",
    "a = cross_val_score(clf, X_test, y_test, cv = kf, scoring = 'roc_auc')\n",
    "print(a.mean())\n",
    "print( 'Время для аппроксимации для SVM', datetime.datetime.now() - start_time )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
